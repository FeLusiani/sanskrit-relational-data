{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ṛgvedavedāṅgajyotiṣa-all.conllu\n",
      "Ṛgveda\n",
      "Ṛgvedakhilāni-all.conllu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sanskrit as sks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for x in sks.data_dir.glob('Ṛgv*'):\n",
    "    print(x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## text: Ṛgvedavedāṅgajyotiṣa\n",
      "## text_id: 33\n",
      "## chapter: ṚVJ, 1\n",
      "## chapter_id: 166\n",
      "\n",
      "# text_line: pañcasaṃvatsaramayaṃ yugādhyakṣaṃ prajāpatim\n",
      "# text_line_id: 47058\n",
      "# text_line_counter: 1\n",
      "# text_line_subcounter: 1\n",
      "1-3\tpañcasaṃvatsaramayaṃ\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "1\t_\tpañcan\tNUM\tNUM\tCase=Cpd\t_\t_\t_\t_\t165692\tpañca\t_\n",
      "2\t_\tsaṃvatsara\tNOUN\tNC\tCase=Cpd\t_\t_\t_\t_\t42265\tsaṃvatsara\t_\n",
      "3\t_\tmaya\tADJ\tJJ\tCase=Acc|Gender=Masc|Number=Sing\t_\t_\t_\t_\t109021\tmayam\t_\n",
      "4-5\tyugādhyakṣaṃ\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "4\t_\tyuga\tNOUN\tNC\tCase=Cpd\t_\t_\t_\t_\t64702\tyuga\t_\n"
     ]
    }
   ],
   "source": [
    "file = sks.data_dir / Path('Ṛgvedavedāṅgajyotiṣa-all.conllu')\n",
    "text = file.read_text()\n",
    "lines = text.split('\\n')\n",
    "for i in range(15):\n",
    "  print(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_line_fields = ['text_id', 'chapter_id', 'text_line', 'text_line_id',\n",
    "                    'text_line_counter', 'text_line_subcounter']\n",
    "\n",
    "word_fields = ['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD',\n",
    "               'DEPREL', 'DEPS', 'MISC', 'LEMMA_ID', 'unsandhied_form', 'semantic_id',\n",
    "               'text_line_id']\n",
    "word_fields_dtype = {'LEMMA_ID':'int32', 'semantic_id':'int32',\n",
    "                    'text_line_id':'int32'}\n",
    "\n",
    "def process_lines(lines):\n",
    "    # text_lines = pd.DataFrame(columns=text_line_fields)\n",
    "    # words = pd.DataFrame(columns=word_fields)\n",
    "    text_lines = []\n",
    "    words = []\n",
    "\n",
    "    text_line = []\n",
    "    chapter_id = None\n",
    "    text_id = None\n",
    "    for l in lines:\n",
    "        if not l:\n",
    "            continue\n",
    "        if l.startswith('#'):\n",
    "            _, key, value = l.split(' ',maxsplit=2)\n",
    "            key = key[:-1] # remove ':'\n",
    "            \n",
    "            \n",
    "            if key == 'text_id':\n",
    "                text_id = value\n",
    "            elif key == 'chapter_id':\n",
    "                chapter_id = value\n",
    "            elif key == 'text_line':\n",
    "                text_line = [text_id, chapter_id, value]\n",
    "            elif key in text_line_fields:\n",
    "                text_line.append(value)\n",
    "\n",
    "            # flush text_line?\n",
    "            if key == 'text_line_subcounter':\n",
    "                text_lines.append(text_line)\n",
    "            continue\n",
    "\n",
    "        row = l.split('\\t')\n",
    "        # composite words do not have the last 3 fields\n",
    "        if len(row) == 10:\n",
    "            row = row + [np.NaN, np.NaN, np.NaN]\n",
    "        # add text_line_id\n",
    "        row.append(text_lines[-1][3])\n",
    "        # append row\n",
    "        words.append(row)\n",
    "    \n",
    "    text_lines = pd.DataFrame(text_lines, columns=text_line_fields)\n",
    "    words = pd.DataFrame(words, columns=word_fields)\n",
    "    return text_lines, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(dir:Path):\n",
    "    total_text_lines = pd.DataFrame()\n",
    "    total_words = pd.DataFrame()\n",
    "    files = list(dir.glob('*.conllu'))\n",
    "    print(f\"n. files:{len(files)}\")\n",
    "    for file in files:\n",
    "        lines = file.read_text().split('\\n')\n",
    "        text_lines, words = process_lines(lines)\n",
    "        total_text_lines = pd.concat([total_text_lines, text_lines])\n",
    "        total_words = pd.concat([total_words, words])\n",
    "    \n",
    "    return total_text_lines, total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines, words = process_files(sks.data_dir)\n",
    "\n",
    "out_txt_ls = sks.data_dir / Path('text_lines.feather')\n",
    "out_words = sks.data_dir / Path('words.feather')\n",
    "\n",
    "text_lines.reset_index(drop=True).to_feather(out_txt_ls)\n",
    "words.reset_index(drop=True).to_feather(out_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = [f for f in sks.data_dir.iterdir() if f.is_dir()]\n",
    "\n",
    "for i, dir in enumerate(target_dirs):\n",
    "    text_lines, words = process_files(dir)\n",
    "    out_txt_ls = dir / Path('text_lines.feather')\n",
    "    out_words = dir / Path('words.feather')\n",
    "\n",
    "    text_lines.reset_index(drop=True).to_feather(out_txt_ls)\n",
    "    words.reset_index(drop=True).to_feather(out_words)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = [f for f in sks.data_dir.iterdir() if f.is_dir()]\n",
    "text_lines_all = pd.read_feather(sks.data_dir / Path('text_lines.feather'))\n",
    "\n",
    "for i, dir in enumerate(target_dirs):\n",
    "    text_lines = pd.read_feather(dir / Path('text_lines.feather'))\n",
    "    text_lines_all = pd.concat([text_lines_all, text_lines])\n",
    "text_lines_all.drop_duplicates().reset_index(drop=True).to_feather('text_lines_all.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = [f for f in sks.data_dir.iterdir() if f.is_dir()]\n",
    "words_all = pd.read_feather(sks.data_dir / Path('words.feather'))\n",
    "\n",
    "for i, dir in enumerate(target_dirs):\n",
    "    words = pd.read_feather(dir / Path('words.feather'))\n",
    "    words_all = pd.concat([words_all, words])\n",
    "\n",
    "words_all.drop_duplicates().reset_index(drop=True).to_feather('words_all.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines_all = pd.read_feather('text_lines_all.feather')\n",
    "words_all = pd.read_feather('words_all.feather')\n",
    "\n",
    "text_lines_all = text_lines_all.astype({'text_line_id':'int'})\n",
    "words_all = words_all.astype({'text_line_id':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv('texts.csv')\n",
    "chapters = pd.read_csv('chapters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th>text_line_id</th>\n",
       "      <th>text_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430829</td>\n",
       "      <td>vyāghrīkandagataṃ vajraṃ dolāyantreṇa pācayet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430833</td>\n",
       "      <td>tadgolake kṣipedvajraṃ ruddhvā gajapuṭe pacet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430842</td>\n",
       "      <td>sa bhīto mūtrayettatra tanmūtre vajramāvapet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430857</td>\n",
       "      <td>nīlaṃ nīlīrasair vajraṃ vinā śudhyati dolayā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430861</td>\n",
       "      <td>vajraṃ vinānyaratnāni mriyante'ṣṭapuṭaiḥ khalu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>ĀK, 2, 8</td>\n",
       "      <td>402908</td>\n",
       "      <td>piṣṭvā tadgolake vajraṃ pūrvapakvaṃ vinikṣipet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>ĀK, 2, 8</td>\n",
       "      <td>402912</td>\n",
       "      <td>tadgole nikṣipedvajraṃ sūtreṇāveṣṭayedbahiḥ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>ĀK, 2, 8</td>\n",
       "      <td>402918</td>\n",
       "      <td>tadgole nikṣipedvajraṃ nimbakārpāsakodravaiḥ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ĀK, 2, 8</td>\n",
       "      <td>402924</td>\n",
       "      <td>vajraṃ tittirimāṃsena veṣṭitaṃ nikṣipenmukhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>ĀK, 2, 8</td>\n",
       "      <td>402934</td>\n",
       "      <td>vajraṃ viśodhitaṃ samyagvastre baddhvā haṭhātp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chapter  text_line_id                                          text_line\n",
       "0      YRā, 1        430829      vyāghrīkandagataṃ vajraṃ dolāyantreṇa pācayet\n",
       "1      YRā, 1        430833      tadgolake kṣipedvajraṃ ruddhvā gajapuṭe pacet\n",
       "2      YRā, 1        430842       sa bhīto mūtrayettatra tanmūtre vajramāvapet\n",
       "3      YRā, 1        430857       nīlaṃ nīlīrasair vajraṃ vinā śudhyati dolayā\n",
       "4      YRā, 1        430861     vajraṃ vinānyaratnāni mriyante'ṣṭapuṭaiḥ khalu\n",
       "..        ...           ...                                                ...\n",
       "249  ĀK, 2, 8        402908     piṣṭvā tadgolake vajraṃ pūrvapakvaṃ vinikṣipet\n",
       "250  ĀK, 2, 8        402912        tadgole nikṣipedvajraṃ sūtreṇāveṣṭayedbahiḥ\n",
       "251  ĀK, 2, 8        402918       tadgole nikṣipedvajraṃ nimbakārpāsakodravaiḥ\n",
       "252  ĀK, 2, 8        402924       vajraṃ tittirimāṃsena veṣṭitaṃ nikṣipenmukhe\n",
       "253  ĀK, 2, 8        402934  vajraṃ viśodhitaṃ samyagvastre baddhvā haṭhātp...\n",
       "\n",
       "[254 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To search the data efficiently, we use the duckDB engine.\n",
    "## In this example, we look for text lines that contain the lemma 'vajra'\n",
    "## in Accusative Case, and a Verb in Present tense.\n",
    "\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "query = \"\"\"\n",
    "select\n",
    "    c.name as chapter, t.text_line_id, t.text_line\n",
    "from\n",
    "    text_lines_all t, chapters c\n",
    "where\n",
    "    c.id = t.chapter_id and\n",
    "    exists\n",
    "    (\n",
    "        select *\n",
    "        from words_all w \n",
    "        where w.LEMMA = 'vajra' and w.FEATS like '%Acc%' and w.text_line_id = t.text_line_id\n",
    "    )\n",
    "    and\n",
    "    exists\n",
    "    (\n",
    "        select *\n",
    "        from words_all w2\n",
    "        where w2.UPOS = 'VERB' and w2.FEATS like '%Tense=Pres%' and w2.text_line_id = t.text_line_id\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "duckdb.query(query).to_df()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7af131e56f57218083654f6f585f596396b8f0c66a10eafd39235300e582eec5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
