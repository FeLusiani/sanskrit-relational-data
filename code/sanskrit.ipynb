{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ṛgvedavedāṅgajyotiṣa-all.conllu\n",
      "Ṛgveda\n",
      "Ṛgvedakhilāni-all.conllu\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sanskrit as sks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for x in sks.data_dir.glob('Ṛgv*'):\n",
    "    print(x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## text: Ṛgvedavedāṅgajyotiṣa\n",
      "## text_id: 33\n",
      "## chapter: ṚVJ, 1\n",
      "## chapter_id: 166\n",
      "\n",
      "# text_line: pañcasaṃvatsaramayaṃ yugādhyakṣaṃ prajāpatim\n",
      "# text_line_id: 47058\n",
      "# text_line_counter: 1\n",
      "# text_line_subcounter: 1\n",
      "1-3\tpañcasaṃvatsaramayaṃ\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "1\t_\tpañcan\tNUM\tNUM\tCase=Cpd\t_\t_\t_\t_\t165692\tpañca\t_\n",
      "2\t_\tsaṃvatsara\tNOUN\tNC\tCase=Cpd\t_\t_\t_\t_\t42265\tsaṃvatsara\t_\n",
      "3\t_\tmaya\tADJ\tJJ\tCase=Acc|Gender=Masc|Number=Sing\t_\t_\t_\t_\t109021\tmayam\t_\n",
      "4-5\tyugādhyakṣaṃ\t_\t_\t_\t_\t_\t_\t_\t_\n",
      "4\t_\tyuga\tNOUN\tNC\tCase=Cpd\t_\t_\t_\t_\t64702\tyuga\t_\n"
     ]
    }
   ],
   "source": [
    "file = sks.data_dir / Path('Ṛgvedavedāṅgajyotiṣa-all.conllu')\n",
    "text = file.read_text()\n",
    "lines = text.split('\\n')\n",
    "for i in range(15):\n",
    "  print(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_line_fields = ['text_id', 'chapter_id', 'text_line', 'text_line_id',\n",
    "                    'text_line_counter', 'text_line_subcounter']\n",
    "\n",
    "word_fields = ['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD',\n",
    "               'DEPREL', 'DEPS', 'MISC', 'LEMMA_ID', 'unsandhied_form', 'semantic_id',\n",
    "               'text_line_id']\n",
    "word_fields_dtype = {'LEMMA_ID':'int32', 'semantic_id':'int32',\n",
    "                    'text_line_id':'int32'}\n",
    "\n",
    "def process_lines(lines):\n",
    "    # text_lines = pd.DataFrame(columns=text_line_fields)\n",
    "    # words = pd.DataFrame(columns=word_fields)\n",
    "    text_lines = []\n",
    "    words = []\n",
    "\n",
    "    text_line = []\n",
    "    chapter_id = None\n",
    "    text_id = None\n",
    "    for l in lines:\n",
    "        if not l:\n",
    "            continue\n",
    "        if l.startswith('#'):\n",
    "            _, key, value = l.split(' ',maxsplit=2)\n",
    "            key = key[:-1] # remove ':'\n",
    "            \n",
    "            \n",
    "            if key == 'text_id':\n",
    "                text_id = value\n",
    "            elif key == 'chapter_id':\n",
    "                chapter_id = value\n",
    "            elif key == 'text_line':\n",
    "                text_line = [text_id, chapter_id, value]\n",
    "            elif key in text_line_fields:\n",
    "                text_line.append(value)\n",
    "\n",
    "            # flush text_line?\n",
    "            if key == 'text_line_subcounter':\n",
    "                text_lines.append(text_line)\n",
    "            continue\n",
    "\n",
    "        row = l.split('\\t')\n",
    "        if len(row) == 10:\n",
    "            row = row + [np.NaN, np.NaN, np.NaN]\n",
    "        # add text_line_id\n",
    "        row.append(text_lines[-1][3])\n",
    "        # append row\n",
    "        words.append(row)\n",
    "    \n",
    "    text_lines = pd.DataFrame(text_lines, columns=text_line_fields)\n",
    "    words = pd.DataFrame(words, columns=word_fields)\n",
    "    return text_lines, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(dir:Path):\n",
    "    total_text_lines = pd.DataFrame()\n",
    "    total_words = pd.DataFrame()\n",
    "    files = list(dir.glob('*.conllu'))\n",
    "    print(f\"n. files:{len(files)}\")\n",
    "    for file in files:\n",
    "        lines = file.read_text().split('\\n')\n",
    "        text_lines, words = process_lines(lines)\n",
    "        # n = text_lines['text_line_id'].nunique() - words['text_line_id'].nunique()\n",
    "        # if  n != 0:\n",
    "        #     print(n)\n",
    "        total_text_lines = pd.concat([total_text_lines, text_lines])\n",
    "        total_words = pd.concat([total_words, words])\n",
    "    \n",
    "    return total_text_lines, total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n. files:224\n"
     ]
    }
   ],
   "source": [
    "text_lines, words = process_files(sks.data_dir)\n",
    "\n",
    "out_txt_ls = sks.data_dir / Path('text_lines.feather')\n",
    "out_words = sks.data_dir / Path('words.feather')\n",
    "\n",
    "text_lines.reset_index(drop=True).to_feather(out_txt_ls)\n",
    "words.reset_index(drop=True).to_feather(out_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n. files:163\n",
      "0\n",
      "n. files:119\n",
      "1\n",
      "n. files:121\n",
      "2\n",
      "n. files:120\n",
      "3\n",
      "n. files:231\n",
      "4\n",
      "n. files:1995\n",
      "5\n",
      "n. files:175\n",
      "6\n",
      "n. files:345\n",
      "7\n",
      "n. files:28\n",
      "8\n",
      "n. files:519\n",
      "9\n",
      "n. files:126\n",
      "10\n",
      "n. files:186\n",
      "11\n",
      "n. files:82\n",
      "12\n",
      "n. files:16\n",
      "13\n",
      "n. files:606\n",
      "14\n",
      "n. files:1028\n",
      "15\n",
      "n. files:285\n",
      "16\n",
      "n. files:20\n",
      "17\n",
      "n. files:95\n",
      "18\n",
      "n. files:166\n",
      "19\n",
      "n. files:39\n",
      "20\n",
      "n. files:35\n",
      "21\n",
      "n. files:28\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "target_dirs = [f for f in sks.data_dir.iterdir() if f.is_dir()]\n",
    "\n",
    "for i, dir in enumerate(target_dirs):\n",
    "    text_lines, words = process_files(dir)\n",
    "    out_txt_ls = dir / Path('text_lines.feather')\n",
    "    out_words = dir / Path('words.feather')\n",
    "\n",
    "    text_lines.reset_index(drop=True).to_feather(out_txt_ls)\n",
    "    words.reset_index(drop=True).to_feather(out_words)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = [f for f in sks.data_dir.iterdir() if f.is_dir()]\n",
    "text_lines_all = pd.read_feather(sks.data_dir / Path('text_lines.feather'))\n",
    "\n",
    "for i, dir in enumerate(target_dirs):\n",
    "    text_line = pd.read_feather(dir / Path('text_lines.feather'))\n",
    "    text_lines_all = pd.concat([text_lines_all, text_line])\n",
    "text_lines_all.drop_duplicates().reset_index(drop=True).to_feather('text_lines_all.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dirs = [f for f in sks.data_dir.iterdir() if f.is_dir()]\n",
    "words_all = pd.read_feather(sks.data_dir / Path('words.feather'))\n",
    "\n",
    "for i, dir in enumerate(target_dirs):\n",
    "    words = pd.read_feather(dir / Path('words.feather'))\n",
    "    words_all = pd.concat([words_all, words])\n",
    "\n",
    "words_all.drop_duplicates().reset_index(drop=True).to_feather('words_all.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lines_all = pd.read_feather('text_lines_all.feather')\n",
    "words_all = pd.read_feather('words_all.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_csv('texts.csv')\n",
    "chapters = pd.read_csv('chapters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th>text_line_id</th>\n",
       "      <th>text_line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430829</td>\n",
       "      <td>vyāghrīkandagataṃ vajraṃ dolāyantreṇa pācayet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430833</td>\n",
       "      <td>tadgolake kṣipedvajraṃ ruddhvā gajapuṭe pacet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430842</td>\n",
       "      <td>sa bhīto mūtrayettatra tanmūtre vajramāvapet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430857</td>\n",
       "      <td>nīlaṃ nīlīrasair vajraṃ vinā śudhyati dolayā</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YRā, 1</td>\n",
       "      <td>430861</td>\n",
       "      <td>vajraṃ vinānyaratnāni mriyante'ṣṭapuṭaiḥ khalu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AgRPar, 1</td>\n",
       "      <td>18130</td>\n",
       "      <td>vajraṃ ca mauktikaṃ śvetaṃ māṇikyaṃ lohitaṃ viduḥ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AgRPar, 1</td>\n",
       "      <td>18136</td>\n",
       "      <td>ratnānām uttamaṃ vajraṃ yo bibharti narottamaḥ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AgRPar, 1</td>\n",
       "      <td>18144</td>\n",
       "      <td>tuṅgaṃ vajraṃ praśaṃsanti ṣaṭkoṇaṃ laghu bhāsk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AgRPar, 1</td>\n",
       "      <td>18167</td>\n",
       "      <td>kṣārāmlair lepayed vajraṃ gharme ca pariśodhayet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ŚpBr, 1, 1, 1</td>\n",
       "      <td>484203</td>\n",
       "      <td>tato devā etaṃ vajraṃ dadṛśuḥ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         chapter text_line_id  \\\n",
       "0         YRā, 1       430829   \n",
       "1         YRā, 1       430833   \n",
       "2         YRā, 1       430842   \n",
       "3         YRā, 1       430857   \n",
       "4         YRā, 1       430861   \n",
       "5      AgRPar, 1        18130   \n",
       "6      AgRPar, 1        18136   \n",
       "7      AgRPar, 1        18144   \n",
       "8      AgRPar, 1        18167   \n",
       "9  ŚpBr, 1, 1, 1       484203   \n",
       "\n",
       "                                           text_line  \n",
       "0      vyāghrīkandagataṃ vajraṃ dolāyantreṇa pācayet  \n",
       "1      tadgolake kṣipedvajraṃ ruddhvā gajapuṭe pacet  \n",
       "2       sa bhīto mūtrayettatra tanmūtre vajramāvapet  \n",
       "3       nīlaṃ nīlīrasair vajraṃ vinā śudhyati dolayā  \n",
       "4     vajraṃ vinānyaratnāni mriyante'ṣṭapuṭaiḥ khalu  \n",
       "5  vajraṃ ca mauktikaṃ śvetaṃ māṇikyaṃ lohitaṃ viduḥ  \n",
       "6     ratnānām uttamaṃ vajraṃ yo bibharti narottamaḥ  \n",
       "7  tuṅgaṃ vajraṃ praśaṃsanti ṣaṭkoṇaṃ laghu bhāsk...  \n",
       "8   kṣārāmlair lepayed vajraṃ gharme ca pariśodhayet  \n",
       "9                      tato devā etaṃ vajraṃ dadṛśuḥ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To search the data efficiently, we use the duckDB engine.\n",
    "## In this example, we look for text lines that contain the lemma 'vajra'\n",
    "## in Accusative Case, and a Verb.\n",
    "## We limit the result to 10 to avoid too many rows.\n",
    "\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "query = \"\"\"\n",
    "select\n",
    "    c.name as chapter, t.text_line_id, t.text_line\n",
    "from\n",
    "    text_lines_all t, chapters c\n",
    "where\n",
    "    c.id = t.chapter_id and\n",
    "    exists\n",
    "    (\n",
    "        select *\n",
    "        from words_all w \n",
    "        where w.LEMMA = 'vajra' and w.FEATS like '%Acc%' and w.text_line_id = t.text_line_id\n",
    "    )\n",
    "    and\n",
    "    exists\n",
    "    (\n",
    "        select *\n",
    "        from words_all w2\n",
    "        where w2.UPOS = 'VERB' and w2.text_line_id = t.text_line_id\n",
    "    )\n",
    "limit\n",
    "    10;\n",
    "\"\"\"\n",
    "\n",
    "duckdb.query(query).to_df()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7af131e56f57218083654f6f585f596396b8f0c66a10eafd39235300e582eec5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
